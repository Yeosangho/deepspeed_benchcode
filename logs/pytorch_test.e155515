[00;33m 	'cuda/11.3' does not supports the {CUDA_MPI}. [0m
[00;34m 	{CUDA_MPI} is only supported in cuda 11.4 version. [0m
[00;34m 	'gcc/10.2.0' supports the following modules [0m
	{MPI}
	'mpi/openmpi-3.1.5' 'mpi/openmpi-4.1.1' 'mpi/mvapich2-2.3.6'
	{CUDA_MPI}
	'cudampi/openmpi-3.1.5' 'cudampi/openmpi-4.1.1' 'cudampi/mvapich2-2.3.6'
[00;31m 	{CUDA_MPI} is only supported in cuda 11.4 version. [0m
	{libraries}
	'hdf4/4.2.13' 'hdf5/1.10.2' 'hdf5/1.12.0' 'lapack/3.7.0' 'lapack/3.10.0' 'ncl/6.5.0' 'netcdf/4.6.1'
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
  0%|          | 0/300 [00:00<?, ?it/s]  0%|          | 0/300 [00:01<?, ?it/s]
  0%|          | 0/300 [00:00<?, ?it/s]  0%|          | 0/300 [00:01<?, ?it/s]
  0%|          | 0/300 [00:00<?, ?it/s]  0%|          | 0/300 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "gpt2_ds.py", line 191, in <module>
    model_engine.backward(loss)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 11, in wrapped_fn
    return func(*args, **kwargs)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 1789, in backward
    self.optimizer.backward(loss, retain_graph=retain_graph)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 1948, in backward
    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/fp16/loss_scaler.py", line 51, in backward
    scaled_loss.backward(retain_graph=retain_graph)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/torch/_tensor.py", line 363, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 800, in reduce_partition_and_remove_grads
    self.reduce_ready_partitions_and_remove_grads(param, i)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 1271, in reduce_ready_partitions_and_remove_grads
    self.reduce_independent_p_g_buckets_and_remove_grads(param, i)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 825, in reduce_independent_p_g_buckets_and_remove_grads
    self.report_ipg_memory_usage("In ipg_remove_grads before reduce_ipg_grads",
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 813, in report_ipg_memory_usage
    percent_of_bucket_size = (100.0 * elem_count) // self.reduce_bucket_size
ZeroDivisionError: float divmod()
Traceback (most recent call last):
  File "gpt2_ds.py", line 191, in <module>
    model_engine.backward(loss)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 11, in wrapped_fn
    return func(*args, **kwargs)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 1789, in backward
    self.optimizer.backward(loss, retain_graph=retain_graph)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 1948, in backward
    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/fp16/loss_scaler.py", line 51, in backward
    scaled_loss.backward(retain_graph=retain_graph)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/torch/_tensor.py", line 363, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 800, in reduce_partition_and_remove_grads
    self.reduce_ready_partitions_and_remove_grads(param, i)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 1271, in reduce_ready_partitions_and_remove_grads
    self.reduce_independent_p_g_buckets_and_remove_grads(param, i)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 825, in reduce_independent_p_g_buckets_and_remove_grads
    self.report_ipg_memory_usage("In ipg_remove_grads before reduce_ipg_grads",
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 813, in report_ipg_memory_usage
    percent_of_bucket_size = (100.0 * elem_count) // self.reduce_bucket_size
ZeroDivisionError: float divmod()
Traceback (most recent call last):
  File "gpt2_ds.py", line 191, in <module>
    model_engine.backward(loss)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 11, in wrapped_fn
    return func(*args, **kwargs)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 1789, in backward
    self.optimizer.backward(loss, retain_graph=retain_graph)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 1948, in backward
    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/fp16/loss_scaler.py", line 51, in backward
    scaled_loss.backward(retain_graph=retain_graph)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/torch/_tensor.py", line 363, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 800, in reduce_partition_and_remove_grads
    self.reduce_ready_partitions_and_remove_grads(param, i)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 1271, in reduce_ready_partitions_and_remove_grads
    self.reduce_independent_p_g_buckets_and_remove_grads(param, i)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 825, in reduce_independent_p_g_buckets_and_remove_grads
    self.report_ipg_memory_usage("In ipg_remove_grads before reduce_ipg_grads",
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 813, in report_ipg_memory_usage
    percent_of_bucket_size = (100.0 * elem_count) // self.reduce_bucket_size
ZeroDivisionError: float divmod()
  0%|          | 0/300 [00:00<?, ?it/s]  0%|          | 0/300 [00:01<?, ?it/s]
  0%|          | 0/300 [00:00<?, ?it/s]  0%|          | 0/300 [00:01<?, ?it/s]
  0%|          | 0/300 [00:00<?, ?it/s]  0%|          | 0/300 [00:01<?, ?it/s]
  0%|          | 0/300 [00:00<?, ?it/s]  0%|          | 0/300 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "gpt2_ds.py", line 191, in <module>
    model_engine.backward(loss)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 11, in wrapped_fn
    return func(*args, **kwargs)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 1789, in backward
    self.optimizer.backward(loss, retain_graph=retain_graph)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 1948, in backward
    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/fp16/loss_scaler.py", line 51, in backward
    scaled_loss.backward(retain_graph=retain_graph)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/torch/_tensor.py", line 363, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 800, in reduce_partition_and_remove_grads
    self.reduce_ready_partitions_and_remove_grads(param, i)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 1271, in reduce_ready_partitions_and_remove_grads
    self.reduce_independent_p_g_buckets_and_remove_grads(param, i)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 825, in reduce_independent_p_g_buckets_and_remove_grads
    self.report_ipg_memory_usage("In ipg_remove_grads before reduce_ipg_grads",
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 813, in report_ipg_memory_usage
    percent_of_bucket_size = (100.0 * elem_count) // self.reduce_bucket_size
ZeroDivisionError: float divmod()
Traceback (most recent call last):
  File "gpt2_ds.py", line 191, in <module>
    model_engine.backward(loss)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 11, in wrapped_fn
    return func(*args, **kwargs)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 1789, in backward
    self.optimizer.backward(loss, retain_graph=retain_graph)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 1948, in backward
    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/fp16/loss_scaler.py", line 51, in backward
    scaled_loss.backward(retain_graph=retain_graph)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/torch/_tensor.py", line 363, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 800, in reduce_partition_and_remove_grads
    self.reduce_ready_partitions_and_remove_grads(param, i)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 1271, in reduce_ready_partitions_and_remove_grads
    self.reduce_independent_p_g_buckets_and_remove_grads(param, i)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 825, in reduce_independent_p_g_buckets_and_remove_grads
    self.report_ipg_memory_usage("In ipg_remove_grads before reduce_ipg_grads",
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 813, in report_ipg_memory_usage
    percent_of_bucket_size = (100.0 * elem_count) // self.reduce_bucket_size
ZeroDivisionError: float divmod()
Traceback (most recent call last):
  File "gpt2_ds.py", line 191, in <module>
    model_engine.backward(loss)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 11, in wrapped_fn
    return func(*args, **kwargs)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 1789, in backward
    self.optimizer.backward(loss, retain_graph=retain_graph)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 1948, in backward
    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/fp16/loss_scaler.py", line 51, in backward
    scaled_loss.backward(retain_graph=retain_graph)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/torch/_tensor.py", line 363, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 800, in reduce_partition_and_remove_grads
    self.reduce_ready_partitions_and_remove_grads(param, i)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 1271, in reduce_ready_partitions_and_remove_grads
    self.reduce_independent_p_g_buckets_and_remove_grads(param, i)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 825, in reduce_independent_p_g_buckets_and_remove_grads
    self.report_ipg_memory_usage("In ipg_remove_grads before reduce_ipg_grads",
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 813, in report_ipg_memory_usage
    percent_of_bucket_size = (100.0 * elem_count) // self.reduce_bucket_size
ZeroDivisionError: float divmod()
Traceback (most recent call last):
  File "gpt2_ds.py", line 191, in <module>
    model_engine.backward(loss)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 11, in wrapped_fn
    return func(*args, **kwargs)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 1789, in backward
    self.optimizer.backward(loss, retain_graph=retain_graph)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 1948, in backward
    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/fp16/loss_scaler.py", line 51, in backward
    scaled_loss.backward(retain_graph=retain_graph)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/torch/_tensor.py", line 363, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 800, in reduce_partition_and_remove_grads
    self.reduce_ready_partitions_and_remove_grads(param, i)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 1271, in reduce_ready_partitions_and_remove_grads
    self.reduce_independent_p_g_buckets_and_remove_grads(param, i)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 825, in reduce_independent_p_g_buckets_and_remove_grads
    self.report_ipg_memory_usage("In ipg_remove_grads before reduce_ipg_grads",
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 813, in report_ipg_memory_usage
    percent_of_bucket_size = (100.0 * elem_count) // self.reduce_bucket_size
ZeroDivisionError: float divmod()
  0%|          | 0/300 [00:00<?, ?it/s]  0%|          | 0/300 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "gpt2_ds.py", line 191, in <module>
    model_engine.backward(loss)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 11, in wrapped_fn
    return func(*args, **kwargs)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 1789, in backward
    self.optimizer.backward(loss, retain_graph=retain_graph)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 1948, in backward
    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/fp16/loss_scaler.py", line 51, in backward
    scaled_loss.backward(retain_graph=retain_graph)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/torch/_tensor.py", line 363, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 800, in reduce_partition_and_remove_grads
    self.reduce_ready_partitions_and_remove_grads(param, i)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 1271, in reduce_ready_partitions_and_remove_grads
    self.reduce_independent_p_g_buckets_and_remove_grads(param, i)
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 825, in reduce_independent_p_g_buckets_and_remove_grads
    self.report_ipg_memory_usage("In ipg_remove_grads before reduce_ipg_grads",
  File "/home01/hpc72a03/.conda/envs/lightning/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 813, in report_ipg_memory_usage
    percent_of_bucket_size = (100.0 * elem_count) // self.reduce_bucket_size
ZeroDivisionError: float divmod()
srun: error: gpu20: task 5: Exited with exit code 1
srun: error: gpu19: tasks 1-3: Exited with exit code 1
srun: error: gpu20: tasks 4,6: Exited with exit code 1
srun: error: gpu19: task 0: Exited with exit code 1
srun: error: gpu20: task 7: Exited with exit code 1
